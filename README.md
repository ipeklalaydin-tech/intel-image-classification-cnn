
# Intel Image Classification (CNN)

Bu proje, [Intel Image Classification](https://www.kaggle.com/datasets/puneet6060/intel-image-classification) veri seti Ã¼zerinde  
**CNN kullanarak Buildings, Forest, Glacier, Mountain, Sea ve Street gÃ¶rÃ¼ntÃ¼lerini sÄ±nÄ±flandÄ±rmayÄ±** hedefler.  

---

## Proje Ã–zeti
Bu Ã§alÄ±ÅŸmaya baÅŸlarken birkaÃ§ farklÄ± deneme yaptÄ±m ve sÃ¼reÃ§ boyunca hem model mimarimi hem de eÄŸitim stratejimi geliÅŸtirdim:  

- **Ä°lk Deneme:** Validation split kullanmadÄ±ÄŸÄ±m iÃ§in model aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) yaptÄ±. Accuracy yaklaÅŸÄ±k **%63** civarÄ±ndaydÄ± ve gerÃ§ek performansÄ± yansÄ±tmÄ±yordu.  
- **Ä°kinci Deneme:** Validation split ekledim ve mimariyi biraz derinleÅŸtirdim. Accuracy **%86**â€™ya kadar Ã§Ä±ktÄ± ama 50 epochâ€™luk eÄŸitimin sadece 15 epochâ€™u bile **1.5 saat** sÃ¼rdÃ¼ â€” yani Ã§ok yavaÅŸtÄ±.  
- **Son Model (Bu Repo):** Daha optimize bir yaklaÅŸÄ±m izledim. Mixed precision ve `tf.data` optimizasyonlarÄ± ekledim. EarlyStopping sayesinde eÄŸitim 15. epoch civarÄ±nda durdu ve:  
  - **EÄŸitim sÃ¼resi:** ~25 dakika  
  - **Validation accuracy:** ~%80  
  - **Test accuracy:** ~%76  

Bu haliyle model hem daha hÄ±zlÄ± hem de daha genellenebilir oldu.

---

## Model & EÄŸitim AyarlarÄ±
- **Model Mimarisinde:**  
  5 adet Conv2D + MaxPooling2D bloÄŸu â†’ Flatten â†’ Dense (512 â†’ 128) â†’ Dropout (0.2)  
  Her konvolÃ¼syon katmanÄ±nda L2 regularizasyonu eklendi.  
- **Optimizer:** Adamax (lr=5e-4)  
- **Loss:** Sparse Categorical Crossentropy  
- **Callbacks:**  
  - `EarlyStopping` (val_accuracy, patience=4)  
  - `ReduceLROnPlateau` (val_loss, factor=0.3)  
- **Validation Split:** %15 - Overfit kontrolÃ¼ saÄŸladÄ±  
- **Batch Size:** 64 - GPU belleÄŸi ve hÄ±z dengesi  
- **Ekstra:** Mixed Precision ile eÄŸitim sÃ¼resi Ã¶nemli Ã¶lÃ§Ã¼de hÄ±zlandÄ±
- 
## ğŸ”§ Hiperparametre Denemeleri

AÅŸaÄŸÄ±daki tablo, farklÄ± hiperparametre kombinasyonlarÄ±yla yapÄ±lan denemeleri ve sonuÃ§larÄ±nÄ± Ã¶zetler:

| Deneme | Learning Rate | Batch Size | Epoch | Dropout | Optimizer | Val Accuracy | Notlar |
|-------|---------------|-----------|-------|---------|-----------|-------------|--------|
| 1 | 0.001 | 32 | 20 | 0.3 | Adam | 0.78 | Overfit gÃ¶zlendi, val. loss arttÄ± |
| 2 | 0.0005 | 64 | 25 | 0.4 | Adam | 0.81 | Daha dengeli sonuÃ§lar, loss daha stabil |
| 3 | 0.0001 | 64 | 30 | 0.4 | Adam | 0.80 | EÄŸitim yavaÅŸladÄ±, iyileÅŸme sÄ±nÄ±rlÄ± |
| 4 | ... | ... | ... | ... | ... | ... | ... |

---

## SonuÃ§lar
- **Validation Accuracy:** ~80%  
- **Test Accuracy:** ~76%  
- **Toplam EÄŸitim SÃ¼resi:** ~25 dakika  

---

## SÃ¼reÃ§te Ã–ÄŸrendiklerim
- Validation split kullanmamak - overfit ve dÃ¼ÅŸÃ¼k genelleme  
- L2 regularizasyon + Dropout eklemek -overfit azaldÄ±
- Mixed precision + prefetching - eÄŸitim sÃ¼resi %70 kÄ±saldÄ±
- IMG_SIZEâ€™Ä± 192x192â€™a dÃ¼ÅŸÃ¼rmek - GPU bellek taÅŸmalarÄ±nÄ± Ã¶nledi 

---

## Gelecek Planlar
- FarklÄ± optimizerâ€™lar (SGD + momentum, AdamW) denemek  
- Transfer learning (EfficientNetB0, ResNet50 gibi) ile doÄŸruluÄŸu artÄ±rmak  
- Veri artÄ±rma (augmentation) stratejilerini daha da geliÅŸtirmek  

## Kaggledan gÃ¶rmek iÃ§in:
https://www.kaggle.com/code/lalayd/son-proje
